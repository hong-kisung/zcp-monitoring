apiVersion: v1
data:
  node.rules: |-
    groups:
    - name: node.rules
      rules:
      - alert: NodeDown
        expr: up{component="node-exporter",job="kubernetes-monitoring-endpoints"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: "{{$labels.instance}}: node-exporter cannot be scraped" 
          description: "{{$labels.instance}}: Prometheus failed to scrape node for more than 2m" 
      - alert: NodeCPUUsage75
        expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{job="kubernetes-nodes-exporters",mode="idle"}[5m])) * 100)) > 75
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: "{{$labels.instance}}: High CPU usage detected"
          description: "{{$labels.instance}}: CPU usage is above 75% (current value is: {{ $value }})"
      - alert: NodeCPUUsage95
        expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{job="kubernetes-nodes-exporters",mode="idle"}[5m])) * 100)) > 95
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: "{{$labels.instance}}: High CPU usage detected"
          description: "{{$labels.instance}}: CPU usage is above 95% (current value is: {{ $value }})"
      - alert: NodeLoadAverage5
        expr: ((node_load5 / count without (cpu, mode) (node_cpu_seconds_total{mode="system"})) > 1)
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: "{{$labels.instance}}: High Load Average detected"
          description: "{{$labels.instance}}: Load Average is high (current value is: {{ $value }})"
      - alert: NodeMemoryUsage75
        expr: (((node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / (node_memory_MemTotal_bytes) * 100)) > 75
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: "{{$labels.instance}}: High memory usage detected"
          description: "{{$labels.instance}}: Memory usage is above 75% (current value is: {{ $value }})"
      - alert: NodeMemoryUsage95
        expr: (((node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes) / (node_memory_MemTotal_bytes) * 100)) > 95
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: "{{$labels.instance}}: High memory usage detected"
          description: "{{$labels.instance}}: Memory usage is above 95% (current value is: {{ $value }})"
      - alert: NodeSwapUsage75
        expr: (((node_memory_SwapTotal_bytes-node_memory_SwapFree_bytes)/node_memory_SwapTotal_bytes)*100) > 75
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: "{{$labels.instance}}: Swap usage detected"
          description: "{{$labels.instance}}: Swap usage usage is above 75% (current value is: {{ $value }})"
      - alert: NodeLowRootDisk75
        expr: ((node_filesystem_size_bytes{mountpoint="/", fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} - node_filesystem_free_bytes{mountpoint="/", fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} ) / node_filesystem_size_bytes{mountpoint="/", fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} * 100) > 75
        for: 30m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: "{{$labels.instance}}: Low Root disk space"
          description: "{{$labels.instance}}: Root disk usage is above 75% (current value is: {{ $value }})"
      - alert: NodeLowRootDisk95
        expr: ((node_filesystem_size_bytes{mountpoint="/", fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} - node_filesystem_free_bytes{mountpoint="/", fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} ) / node_filesystem_size_bytes{mountpoint="/", fstype!~"rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs"} * 100) > 95
        for: 30m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: "{{$labels.instance}}: Low Root disk space"
          description: "{{$labels.instance}}: Root disk usage is above 95% (current value is: {{ $value }})"  
  kube-apiserver.rules: |-
    groups:
    - name: kube-apiserver.rules
      rules:
      - alert: APIServerDown
        expr: up{job="kubernetes-apiservers"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: API server unreachable
          description: Prometheus failed to scrape API server
      - alert: APIServerErrorsHigh
        expr: irate(apiserver_request_count{code=~"^(?:5..)$"}[5m]) / irate(apiserver_request_count[5m]) * 100 > 5
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: API server Errors High
          description: "API server returns errors for {{$value}}% of requests summary: API server request errors"
      - alert: APIServerLatencyHigh
        expr: ((irate(apiserver_request_latencies_sum[5m]) / irate(apiserver_request_latencies_count[5m])) / 1e+06) > 2000
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: API server Latency High
          description: "API server latency High above 2s (current value: {{ $value }}ms"
  kubelet.rules: |-
    groups:
    - name: kubelet.rules
      rules:
      - alert: K8SKubeletDown
        expr: up{job="kubernetes-nodes"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          description: Prometheus failed to scrape {{ $labels.instance }} of kubelets.
          summary: Kubelets cannot be scraped
      - alert: K8SKubeletTooManyPods
        expr: kubelet_running_pod_count > 100
        for: 10m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          description: Kubelet {{$labels.instance}} is running {{$value}} pods, close to the limit of 110
          summary: Kubelet is close to pod limit
  etcd.rules: |-
    groups:
    - name: etcd.rules
      rules:
      - alert: ETCD_Down
        expr: up{job="etcd"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: ETCD server unreachable
          description: Prometheus failed to scrape ETCD server
      - alert: ETCD_NoLeader
        expr: etcd_server_has_leader{job="etcd"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: ETCD Member has no leader
          description: ETCD Member {{ $labels.instance }} has no leader
      - alert: ETCD_InsufficientMembers
        expr: count(up{job="etcd"} == 0) > (count(up{job="etcd"}) / 2 - 1)
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: ETCD server insufficient members
          description: If one more etcd member goes down the cluster will be unavailable
      - alert: ETCD_HighNumberOfLeaderChanges
        expr: increase(etcd_server_leader_changes_seen_total{job="etcd"}[1h]) > 3
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: ETCD a high number of leader changes within the etcd cluster are happening
          description: ETCD instance {{ $labels.instance }} has seen {{ $value }} leader changes within the last hour
  kube-state-metrics.rules: |-
    groups:
    - name: kube-state-metrics.rules
      rules:
      - alert: K8SNodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          description: The Kubelet on {{ $labels.node }} has not checked in with the API, or has set itself to NotReady, for more than 2m
          summary: Node status is NotReady
      - alert: K8SNodeOutOfDisk
        expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          description: "{{ $labels.node }} is insufficient free space on the node for adding new pods"
          summary: Node ran out of disk space.
      - alert: K8SNodeMemoryPressure
        expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          description: "{{ $labels.node }} memory is low"
          summary: Node is under memory pressure.
      - alert: K8SNodePIDPressure
        expr: kube_node_status_condition{condition="PIDPressure",status="true"} == 1
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          description: "{{ $labels.node }} is too many processes on the node"
          summary: Node is under PID pressure.
      - alert: K8SNodeDiskPressure
        expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          description: "{{ $labels.node }} disk capacity is low"
          summary: Node is under disk pressure.
      - alert: PodFrequentlyRestarting
        expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
        for: 10m
        labels:
          channel: sk-cps-ops
          severity: warning
        annotations:
          summary: Pod is restarting frequently
          description: Pod {{$labels.namespace}}/{{$labels.pod}} is was restarted {{$value}} times within the last hour
  prometheus.rules: |-
    groups:
    - name: prometheus.rules
      rules:
      - alert: PrometheusFailedReload
        expr: prometheus_config_last_reload_successful == 0
        for: 10m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: Prometheus configuration reload has failed 
          description: Reloading Prometheus' configuration has failed for {{ $labels.namespace}}/{{ $labels.pod}}.
      - alert: PrometheusErrorSendingAlerts
        expr: rate(prometheus_notifications_errors_total[5m]) / rate(prometheus_notifications_sent_total[5m]) > 0.01
        for: 10m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: Errors while sending alerts from Prometheus
          description: Errors while sending alerts from Prometheus to Alertmanager {{$labels.Alertmanager}}
      - alert: PrometheusNotConnectedtoAlertmanagers
        expr: prometheus_notifications_alertmanagers_discovered < 1
        for: 10m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: Prometheus is not connected to any Alertmanagers
          description: Prometheus is not connected to any Alertmanagers
  alertmanager.rules: |-
    groups:
    - name: alertmanager.rules
      rules:
      - alert: AlertmanagerFailedReload
        expr: alertmanager_config_last_reload_successful == 0
        for: 10m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          description: Reloading Alertmanager's configuration has failed
          summary: Alertmanager configuration reload has failed
  component-up-monitoring.rules: |-
    groups:
    - name: component-up-monitoring.rules
      rules:
      - alert: ZCPMonitoringDown
        expr: up{component=~"alertmanager|blackbox-exporter|grafana|kube-state-metrics|prometheus"} == 0
        for: 2m
        labels:
          channel: sk-cps-ops
          severity: critical
        annotations:
          summary: ZCP Monitoring Component Down 
          description: ZCP Monitoring Component Down has failed for {{ $labels.component }}
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: zcp-system
